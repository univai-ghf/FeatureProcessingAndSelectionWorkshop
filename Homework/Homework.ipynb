{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "#ordinal encoding\n",
    "# with open-source packages\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Get your Dataset \n",
    "def getData():\n",
    "    cols=['symboling','stroke','compressionratio','citympg','enginelocation','aspiration']\n",
    "    df=pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/Nandata1.csv',usecols=cols)\n",
    "    return df\n",
    "\n",
    "#1.1 Read the Dataset From the function above\n",
    "df=________   #Your Code Here\n",
    "\n",
    "\n",
    "\n",
    "#1.2 View the first five rows of your Data set \n",
    "\n",
    " #Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Print the shape of your data \n",
    "\n",
    "#Your Code Here\n",
    "\n",
    "#2.2 Check for missing values in your data \n",
    "\n",
    "#Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 Check the Cardinality of the Data \n",
    "\n",
    "#Your code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1 Check Distribution of the columns stroke,compressionratio,citympg\n",
    "\n",
    "#Your code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Plot Q-Q plots for each variable and infer if they follow a normal distribution or not\n",
    "\n",
    "#Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1) Impute the missing values in categorical variables('aspiration','enginelocation') using SimpleImputer.set the argument \"strategy\" = 'most_frequent'.\n",
    "\n",
    "\n",
    "categorical_cols = ['aspiration','enginelocation']\n",
    "\n",
    "#your code here \n",
    "\n",
    "categorical_imputer =  ________________# use simple imputer \n",
    "\n",
    "#fit categorical imputer on categorical columns\n",
    "categorical_imputer._____ #(fit only on categorical data)\n",
    "\n",
    "#transform categorical columns, and assign the values to df[categorical_cols]\n",
    "df[categorical_cols] =categorical_imputer._______   #transform only on categorical data \n",
    "\n",
    "\n",
    "#5.2) Impute the missing values in numerical variables('symboling','stroke','compressionratio','citympg') using SimpleImputer.set the argument \"strategy\" = 'mean'.\n",
    "\n",
    "numerical_cols = ['symboling','stroke','compressionratio','citympg']\n",
    "\n",
    "#your code here \n",
    "\n",
    "numerical_imputer = _________  # use simple imputer \n",
    "\n",
    "#fit numerical imputer on numerical columns\n",
    "numerical_imputer.______ #(fit only on numerical cols)\n",
    "\n",
    "#transform numerical columns, and assign the values to df[numerical]\n",
    "df[numerical_cols] = numerical_imputer._____   #transform only on numerical data \n",
    "\n",
    "#5.3 Now check the count of missing values in the dataframe again using \"df.isnull().sum()\". Make sure that there is no missing values present.\n",
    "\n",
    "#Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.1 Log Transform ['stroke','compressionratio','citympg'] these columns \n",
    "\n",
    "#Your Code Here \n",
    "df[['stroke','compressionratio','citympg']]=np.log(________)\n",
    "\n",
    "#6.2 One Hot Encode ['aspiration','enginelocation'] columns and store in a variable dummy using pandas get_dummies function.\n",
    "#Concatenate this variable dummy with the dataframe\n",
    "\n",
    "dummy=pd.get_dummies(__________)\n",
    "\n",
    "df=pd.concat(______________)\n",
    "\n",
    "\n",
    "#6.2 Drop ['aspiration','enginelocation'] from the Data Frame and save the changes\n",
    "\n",
    "#Your Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Print the Final Dataset \n",
    "\n",
    "#Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 Repeat 4.1 on the transformed datastet\n",
    "\n",
    "#Your Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 Print the mean of the columns stroke and citympg of the transformed data \n",
    "\n",
    "#Your code here "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "423d5580e5a70cfacc6726872e3658ff2836f3f7c1fd3c3256b5e5f36e2fe05e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
