{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecac783f",
   "metadata": {},
   "source": [
    "# Removing Observation with Missing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5d143f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to split the data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to impute missing data with sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# to impute missing data with feature-engine\n",
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "from feature_engine.imputation import MeanMedianImputer , CategoricalImputer, ArbitraryNumberImputer, RandomSampleImputer, EndTailImputer\n",
    "\n",
    "\n",
    "# to impute missing data with sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# to show all the columns of the dataframe in the notebeook\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e13ff590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7019d967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A15    0.000000\n",
       "A16    0.000000\n",
       "A4     0.008696\n",
       "A5     0.008696\n",
       "A6     0.013043\n",
       "A7     0.013043\n",
       "A1     0.017391\n",
       "A2     0.017391\n",
       "A14    0.018841\n",
       "A3     0.133333\n",
       "A8     0.133333\n",
       "A9     0.133333\n",
       "A10    0.133333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's inspect the percentage of missing values in each variable\n",
    "\n",
    "data.isnull().mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "de72215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a complete case data set\n",
    "\n",
    "data_cca = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3ed8e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total observations: 690\n",
      "Number of observations with complete cases: 564\n"
     ]
    }
   ],
   "source": [
    "print('Number of total observations: {}'.format(len(data)))\n",
    "print('Number of observations with complete cases: {}'.format(len(data_cca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7dee903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also indicate for which variables we would like the complete\n",
    "# cases\n",
    "\n",
    "data_cca = data.dropna(subset=[\n",
    "    'A1',\n",
    "    'A2',\n",
    "    'A6',\n",
    "    'A7',\n",
    "    'A14',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1d302108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total observations: 690\n",
      "Number of observations with complete cases: 653\n"
     ]
    }
   ],
   "source": [
    "print('Number of total observations: {}'.format(len(data)))\n",
    "print('Number of observations with complete cases: {}'.format(len(data_cca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945362d",
   "metadata": {},
   "source": [
    "# Performing Mean or Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de543491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "08aed89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 15), (207, 15))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d384ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.008282\n",
       "A2     0.022774\n",
       "A3     0.140787\n",
       "A4     0.008282\n",
       "A5     0.008282\n",
       "A6     0.008282\n",
       "A7     0.008282\n",
       "A8     0.140787\n",
       "A9     0.140787\n",
       "A10    0.140787\n",
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A14    0.014493\n",
       "A15    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data per variable\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1723ef",
   "metadata": {},
   "source": [
    "## Mean / median imputation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d9ff54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA in indicated numerical variables\n",
    "\n",
    "for var in ['A2', 'A3', 'A8', 'A11', 'A15']:\n",
    "\n",
    "    value = X_train[var].median()\n",
    "\n",
    "    X_train[var] = X_train[var].fillna(value)\n",
    "    X_test[var] = X_test[var].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "812fd3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     0\n",
       "A3     0\n",
       "A8     0\n",
       "A11    0\n",
       "A15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of missing values in imputed variables\n",
    "\n",
    "X_train[['A2', 'A3', 'A8', 'A11', 'A15']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2bdc7b",
   "metadata": {},
   "source": [
    "## Mean / median imputation with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2582de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['A2', 'A3', 'A8', 'A11', 'A15']],\n",
    "    data['A16'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e5680008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.835,  2.75 ,  1.   ,  0.   ,  6.   ])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a median imputation object with SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# let's fit the imputer to the train set\n",
    "# the imputer will learn the median of all variables\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# we can look at the learnt medians:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e046f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we impute the train and test sets\n",
    "# NOTE: the data is returned as a numpy array!!!\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "980c202c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that missing values were removed\n",
    "\n",
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d402a",
   "metadata": {},
   "source": [
    "## Mean / Median imputation with Feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "494b596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6cb09b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanMedianImputer(variables=['A2', 'A3', 'A8', 'A11', 'A15'])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a median imputer\n",
    "\n",
    "median_imputer = MeanMedianImputer(imputation_method='median',\n",
    "                                   variables=['A2', 'A3', 'A8', 'A11', 'A15'])\n",
    "\n",
    "median_imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5f02f365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A2': 28.835, 'A3': 2.75, 'A8': 1.0, 'A11': 0.0, 'A15': 6.0}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's inspect the dictionary with the mappings for each variable\n",
    "median_imputer.imputer_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "150a725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X_train = median_imputer.transform(X_train)\n",
    "X_test = median_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f1aa7bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     0.0\n",
       "A3     0.0\n",
       "A8     0.0\n",
       "A11    0.0\n",
       "A15    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that null values were replaced\n",
    "X_train[['A2', 'A3', 'A8', 'A11', 'A15']].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c504d4",
   "metadata": {},
   "source": [
    "## Mean / median imputation with Sklearn selecting features to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "32d22dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4127c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to make a list with the numerical vars\n",
    "numeric_features_mean = ['A2', 'A3', 'A8', 'A11', 'A15']\n",
    "\n",
    "# then we instantiate the imputer within a pipeline\n",
    "numeric_mean_imputer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "])\n",
    "\n",
    "# then we put the features list and the imputer in the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('mean_imputer', numeric_mean_imputer, numeric_features_mean)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "586f761a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('mean_imputer',\n",
       "                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n",
       "                                 ['A2', 'A3', 'A8', 'A11', 'A15'])])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we fit the preprocessor\n",
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bc271136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we impute the data\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e866de22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.08, 3.0, 2.375, ..., 't', 'g', 396.0],\n",
       "       [15.92, 2.875, 0.085, ..., 'f', 'g', 120.0],\n",
       "       [36.33, 2.125, 0.085, ..., 'f', 'g', 50.0],\n",
       "       ...,\n",
       "       [19.58, 0.665, 1.665, ..., 'f', 'g', 220.0],\n",
       "       [22.83, 2.29, 2.29, ..., 't', 'g', 140.0],\n",
       "       [40.58, 3.29, 3.5, ..., 't', 's', 400.0]], dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that Scikit-Learn transformers return NumPy arrays!!\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3ac84",
   "metadata": {},
   "source": [
    "# Implementing a Mode or Frequent Category Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4f41adbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "da97fb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 15), (207, 15))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1965d886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.008282\n",
       "A2     0.022774\n",
       "A3     0.140787\n",
       "A4     0.008282\n",
       "A5     0.008282\n",
       "A6     0.008282\n",
       "A7     0.008282\n",
       "A8     0.140787\n",
       "A9     0.140787\n",
       "A10    0.140787\n",
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A14    0.014493\n",
       "A15    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data within those variables\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e012054",
   "metadata": {},
   "source": [
    "## Frequent category imputation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "73b67cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA in some categorical variables\n",
    "\n",
    "for var in ['A4', 'A5', 'A6', 'A7']:\n",
    "\n",
    "    value = X_train[var].mode()[0]\n",
    "\n",
    "    X_train[var] = X_train[var].fillna(value)\n",
    "    X_test[var] = X_test[var].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d28d2dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A4    0\n",
       "A5    0\n",
       "A6    0\n",
       "A7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of missing values\n",
    "\n",
    "X_train[['A4', 'A5', 'A6', 'A7']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8764b1",
   "metadata": {},
   "source": [
    "## Frequent category imputation with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f188e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['A4', 'A5', 'A6', 'A7']], data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8c324180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['u', 'g', 'c', 'v'], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a frequent category imputation object with SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# we fit the imputer to the train set\n",
    "# the imputer will learn the mode of all variables\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# we can look at the learnt modes:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9f70d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we impute the train and test set\n",
    "# NOTE: the data is returned as a numpy array!!!\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2f94bb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e537abd",
   "metadata": {},
   "source": [
    "## Frequent category imputation with Feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fce8811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c9cb2d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalImputer(imputation_method='frequent',\n",
       "                   variables=['A4', 'A5', 'A6', 'A7'])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a frequent imputation transformer\n",
    "\n",
    "mode_imputer = CategoricalImputer(variables=['A4', 'A5', 'A6', 'A7'], imputation_method='frequent')\n",
    "\n",
    "mode_imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "43d219e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A4': 'u', 'A5': 'g', 'A6': 'c', 'A7': 'v'}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary with the mappings for each variable\n",
    "mode_imputer.imputer_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b4087885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X_train = mode_imputer.transform(X_train)\n",
    "X_test = mode_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c0028de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A4    0.0\n",
       "A5    0.0\n",
       "A6    0.0\n",
       "A7    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['A4', 'A5', 'A6', 'A7']].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b973e",
   "metadata": {},
   "source": [
    "## Frequent category imputation with Sklearn selecting features to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4b6e24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "\n",
    "# let's separate into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8de58985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we make a lists with the features\n",
    "# to be imputed\n",
    "\n",
    "categoric_features = ['A4', 'A5', 'A6', 'A7']\n",
    "\n",
    "# then we instantiate the imputer within a pipeline\n",
    "\n",
    "categoric_imputer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "# then we put the features list and the imputer together\n",
    "# using the column transformer\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('frequent_imputer', categoric_imputer, categoric_features)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "53263f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('frequent_imputer',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent'))]),\n",
       "                                 ['A4', 'A5', 'A6', 'A7'])])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we fit the preprocessor\n",
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3deb5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we can impute the data\n",
    "\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "72633b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['u', 'g', 'c', ..., 'g', 396.0, 4159],\n",
       "       ['u', 'g', 'q', ..., 'g', 120.0, 0],\n",
       "       ['y', 'p', 'w', ..., 'g', 50.0, 1187],\n",
       "       ...,\n",
       "       ['u', 'g', 'w', ..., 'g', 220.0, 5],\n",
       "       ['u', 'g', 'q', ..., 'g', 140.0, 2384],\n",
       "       ['u', 'g', 'm', ..., 's', 400.0, 0]], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# be carefutl that Scikit-Learn transformers return NumPy arrays!!\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2288f",
   "metadata": {},
   "source": [
    "# Replacing Missing Values With an Arbitrary Number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0c5b58f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "609ce023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 15), (207, 15))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ccd177e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.008282\n",
       "A2     0.022774\n",
       "A3     0.140787\n",
       "A4     0.008282\n",
       "A5     0.008282\n",
       "A6     0.008282\n",
       "A7     0.008282\n",
       "A8     0.140787\n",
       "A9     0.140787\n",
       "A10    0.140787\n",
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A14    0.014493\n",
       "A15    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data per variable\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6a47d",
   "metadata": {},
   "source": [
    "## Arbitrary imputation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "98e5d4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     76.750\n",
       "A3     26.335\n",
       "A8     20.000\n",
       "A11    67.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the maximum value per variable\n",
    "X_train[['A2','A3', 'A8', 'A11']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e4e14c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA with 99 in indicated numerical variables\n",
    "\n",
    "for var in ['A2','A3', 'A8', 'A11']:\n",
    "    \n",
    "    X_train[var].fillna(99, inplace=True)\n",
    "    X_test[var].fillna(99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "943f63eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     0\n",
       "A3     0\n",
       "A8     0\n",
       "A11    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of missing values\n",
    "X_train[['A2','A3', 'A8', 'A11']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c45df6",
   "metadata": {},
   "source": [
    "## Arbitrary imputation with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b8c8c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['A2', 'A3', 'A8', 'A11']],\n",
    "    data['A16'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "87669841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([99., 99., 99., 99.])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the simple imputer\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=99)\n",
    "\n",
    "# we fit the imputer to the train set\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# we can look at the constant values:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b12bbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we impute the train and test set\n",
    "# NOTE: the data is returned as a numpy array!!!\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d379950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that missing values were removed\n",
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818941f",
   "metadata": {},
   "source": [
    "## Arbitrary imputation imputation with feature engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ec006961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ed981318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArbitraryNumberImputer(arbitrary_number=99, variables=['A2', 'A3', 'A8', 'A11'])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create an arbitrary value imputer\n",
    "\n",
    "imputer = ArbitraryNumberImputer(\n",
    "    arbitrary_number=99, variables=['A2','A3', 'A8', 'A11'])\n",
    "\n",
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0ce8d395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary with the mappings for each variable\n",
    "imputer.arbitrary_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "46c7f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "462a5119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     0.0\n",
       "A3     0.0\n",
       "A8     0.0\n",
       "A11    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that null values were replaced\n",
    "X_train[['A2','A3', 'A8', 'A11']].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9242e",
   "metadata": {},
   "source": [
    "## Arbitrary imputation imputation with Sklearn selecting features to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1ef32189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1),data['A16' ], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dd1abcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to make a list with the numerical vars\n",
    "features_arbitrary = ['A2', 'A3', 'A8', 'A11']\n",
    "features_mean = ['A15']\n",
    "\n",
    "# then we instantiate the imputer within a pipeline\n",
    "arbitrary_imputer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=99))])\n",
    "\n",
    "mean_imputer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "# then we put the features list and the imputer in\n",
    "# the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('arbitrary_imputer', arbitrary_imputer, features_arbitrary),\n",
    "    ('mean_imputer', mean_imputer, features_mean)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4b853cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('arbitrary_imputer',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value=99,\n",
       "                                                                strategy='constant'))]),\n",
       "                                 ['A2', 'A3', 'A8', 'A11']),\n",
       "                                ('mean_imputer',\n",
       "                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n",
       "                                 ['A15'])])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we fit the preprocessor\n",
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c2aada9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we impute the data\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7c714fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.08, 3.0, 2.375, ..., 't', 'g', 396.0],\n",
       "       [15.92, 2.875, 0.085, ..., 'f', 'g', 120.0],\n",
       "       [36.33, 2.125, 0.085, ..., 'f', 'g', 50.0],\n",
       "       ...,\n",
       "       [19.58, 0.665, 1.665, ..., 'f', 'g', 220.0],\n",
       "       [22.83, 2.29, 2.29, ..., 't', 'g', 140.0],\n",
       "       [40.58, 3.29, 3.5, ..., 't', 's', 400.0]], dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that Scikit-Learn transformers return NumPy arrays!!\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c3e71",
   "metadata": {},
   "source": [
    "# Capturing Missing Values in a bespoke Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c41fd5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2e137bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 15), (207, 15))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4b668f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.008282\n",
       "A2     0.022774\n",
       "A3     0.140787\n",
       "A4     0.008282\n",
       "A5     0.008282\n",
       "A6     0.008282\n",
       "A7     0.008282\n",
       "A8     0.140787\n",
       "A9     0.140787\n",
       "A10    0.140787\n",
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A14    0.014493\n",
       "A15    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data per variable\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec92f6",
   "metadata": {},
   "source": [
    "## Adding a bespoke category with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ac7407a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA in some categorical variables\n",
    "\n",
    "for var in ['A4', 'A5', 'A6', 'A7']:\n",
    "\n",
    "    X_train[var].fillna('Missing', inplace=True)\n",
    "    X_test[var].fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "893f6f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A4    0\n",
       "A5    0\n",
       "A6    0\n",
       "A7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of missing values\n",
    "X_train[['A4', 'A5', 'A6', 'A7']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de758365",
   "metadata": {},
   "source": [
    "## Adding a bespoke category with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cdd5a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['A4', 'A5', 'A6', 'A7']], data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "322fef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Missing', 'Missing', 'Missing', 'Missing'], dtype=object)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the simple imputer\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='Missing')\n",
    "\n",
    "# we fit the imputer to the train set\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# we can look at the new category:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6307be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we impute the train and test set\n",
    "# NOTE: the data is returned as a numpy array!!!\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b8fdfea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81153642",
   "metadata": {},
   "source": [
    "## Adding a bespoke category with feature engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "325ca70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0faed1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalImputer(variables=['A4', 'A5', 'A6', 'A7'])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = CategoricalImputer(variables=['A4', 'A5', 'A6', 'A7'])\n",
    "\n",
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b7f5715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "256670d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A4    0.0\n",
       "A5    0.0\n",
       "A6    0.0\n",
       "A7    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['A4', 'A5', 'A6', 'A7']].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cef200",
   "metadata": {},
   "source": [
    "## Adding a bespoke category with Sklearn selecting features to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2ffe2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "42522d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we make a lists with the features to be imputed\n",
    "features_arbitrary = ['A4', 'A5']\n",
    "features_mode = ['A6', 'A7']\n",
    "\n",
    "# then we instantiate the imputer within a pipeline\n",
    "arbitrary_imputer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing'))])\n",
    "\n",
    "mode_imputer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "# then we put the features list and the imputers in\n",
    "# the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('arbitrary_imputer', arbitrary_imputer, features_arbitrary),\n",
    "    ('mean_imputer', mode_imputer, features_mode)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "87e9c888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('arbitrary_imputer',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='Missing',\n",
       "                                                                strategy='constant'))]),\n",
       "                                 ['A4', 'A5']),\n",
       "                                ('mean_imputer',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent'))]),\n",
       "                                 ['A6', 'A7'])])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we fit the preprocessor\n",
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e6bdffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we can impute the data\n",
    "\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "72727e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['u', 'g', 'c', ..., 'g', 396.0, 4159],\n",
       "       ['u', 'g', 'q', ..., 'g', 120.0, 0],\n",
       "       ['y', 'p', 'w', ..., 'g', 50.0, 1187],\n",
       "       ...,\n",
       "       ['u', 'g', 'w', ..., 'g', 220.0, 5],\n",
       "       ['u', 'g', 'q', ..., 'g', 140.0, 2384],\n",
       "       ['u', 'g', 'm', ..., 's', 400.0, 0]], dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# be carefutl that Scikit-Learn transformers return NumPy arrays!!\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab81a05",
   "metadata": {},
   "source": [
    "# Replacing Missing Values by a value at the end of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28211ff",
   "metadata": {},
   "source": [
    "## End tail imputation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4e73805c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "56389e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 15), (207, 15))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c867d5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.008282\n",
       "A2     0.022774\n",
       "A3     0.140787\n",
       "A4     0.008282\n",
       "A5     0.008282\n",
       "A6     0.008282\n",
       "A7     0.008282\n",
       "A8     0.140787\n",
       "A9     0.140787\n",
       "A10    0.140787\n",
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A14    0.014493\n",
       "A15    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data per variable\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0f17b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA in indicated numerical variables\n",
    "# using inter-quantal range proximity rule \n",
    "\n",
    "for var in ['A2', 'A3', 'A8', 'A11', 'A15']:\n",
    "\n",
    "    IQR = X_train[var].quantile(0.75) - X_train[var].quantile(0.25)\n",
    "    value = X_train[var].quantile(0.75) + 1.5 * IQR\n",
    "\n",
    "    X_train[var] = X_train[var].fillna(value)\n",
    "    X_test[var] = X_test[var].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "aacef3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     0\n",
       "A3     0\n",
       "A8     0\n",
       "A11    0\n",
       "A15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check absence of missing values\n",
    "X_train[['A2', 'A3', 'A8', 'A11', 'A15']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48193c39",
   "metadata": {},
   "source": [
    "## End tail imputation with Feature Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4c6b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8b9a6b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EndTailImputer(variables=['A2', 'A3', 'A8', 'A11', 'A15'])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a median imputer\n",
    "\n",
    "# imputer = EndTailImputer(distribution='skewed', tail='right',\n",
    "#                          variables=['A2', 'A3', 'A8', 'A11', 'A15'])\n",
    "\n",
    "imputer = EndTailImputer(tail='right',\n",
    "                         variables=['A2', 'A3', 'A8', 'A11', 'A15'])\n",
    "\n",
    "\n",
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0077934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A2': 68.35771260807589,\n",
       " 'A3': 19.98993346546277,\n",
       " 'A8': 12.418567732660225,\n",
       " 'A11': 18.320547522636247,\n",
       " 'A15': 12740.850618383225}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary with the mappings for each variable\n",
    "imputer.imputer_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c8229670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "249c24ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     0.0\n",
       "A3     0.0\n",
       "A8     0.0\n",
       "A11    0.0\n",
       "A15    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that null values were replaced\n",
    "X_train[['A2', 'A3', 'A8', 'A11', 'A15']].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9364e",
   "metadata": {},
   "source": [
    "# Implementing Random Sample Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6325b6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "117104cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 15), (207, 15))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "811d6c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.008282\n",
       "A2     0.022774\n",
       "A3     0.140787\n",
       "A4     0.008282\n",
       "A5     0.008282\n",
       "A6     0.008282\n",
       "A7     0.008282\n",
       "A8     0.140787\n",
       "A9     0.140787\n",
       "A10    0.140787\n",
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A14    0.014493\n",
       "A15    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data within those variables\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea17ad",
   "metadata": {},
   "source": [
    "## Random Sample imputation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "700fab63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract a random sample (as many values as missing values in the variable)\n",
    "\n",
    "number_missing_values = X_train['A2'].isnull().sum()\n",
    "number_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6705b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a random sample (as many values as missing values in the variable)\n",
    "\n",
    "random_sample_train = X_train['A2'].dropna().sample(number_missing_values, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ec228011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([97, 500, 329, 83, 254, 608, 445, 450, 515, 286, 86], dtype='int64')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-index the random sample so that we can join it to our original data\n",
    "\n",
    "random_sample_train.index = X_train[X_train['A2'].isnull()].index\n",
    "\n",
    "random_sample_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e4bbc404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the missing values\n",
    "X_train.loc[X_train['A2'].isnull(), 'A2'] = random_sample_train\n",
    "\n",
    "X_train['A2'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "28d79b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1    0\n",
       "A3    0\n",
       "A4    0\n",
       "A5    0\n",
       "A6    0\n",
       "A7    0\n",
       "A8    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat in a loop for the rest of the variables\n",
    "# and for both train and test set\n",
    "\n",
    "for var in ['A1', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8']:\n",
    "\n",
    "    # extract a random sample\n",
    "    random_sample_train = X_train[var].dropna().sample(\n",
    "        X_train[var].isnull().sum(), random_state=0)\n",
    "\n",
    "    random_sample_test = X_train[var].dropna().sample(\n",
    "        X_test[var].isnull().sum(), random_state=0)\n",
    "\n",
    "    # re index the random sample\n",
    "    random_sample_train.index = X_train[X_train[var].isnull()].index\n",
    "    random_sample_test.index = X_test[X_test[var].isnull()].index\n",
    "\n",
    "    # replace the NA \n",
    "    X_train.loc[X_train[var].isnull(), var] = random_sample_train\n",
    "    X_test.loc[X_test[var].isnull(), var] = random_sample_test\n",
    "    \n",
    "# check missing data\n",
    "X_train[['A1', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a5fe2",
   "metadata": {},
   "source": [
    "## Random Sample imputation with Feature Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3f18b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "39485b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomSampleImputer()"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a random sample imputer\n",
    "\n",
    "imputer = RandomSampleImputer()\n",
    "\n",
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c0c26967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data - replace the missing values\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "981f137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.0\n",
       "A2     0.0\n",
       "A3     0.0\n",
       "A4     0.0\n",
       "A5     0.0\n",
       "A6     0.0\n",
       "A7     0.0\n",
       "A8     0.0\n",
       "A9     0.0\n",
       "A10    0.0\n",
       "A11    0.0\n",
       "A12    0.0\n",
       "A13    0.0\n",
       "A14    0.0\n",
       "A15    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that null values were replaced\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d323dc",
   "metadata": {},
   "source": [
    "## Random Sampling seeding on variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6dc98a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e2d0d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_obs = RandomSampleImputer(random_state=['A8', 'A3'], seed='observation', seeding_method='add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3c72dc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomSampleImputer(random_state=['A8', 'A3'], seed='observation')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer_obs.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3fa0de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tt = imputer_obs.transform(X_train)\n",
    "X_test_tt = imputer_obs.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9b8ce",
   "metadata": {},
   "source": [
    "# Adding a Missing Value Indicator Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e1ed5ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8   A9  A10  A11 A12 A13    A14  A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25    t    t    1   f   g  202.0    0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04    t    t    6   f   g   43.0  560    1\n",
       "2  a  24.50    NaN  u  g  q  h   NaN  NaN  NaN    0   f   g  280.0  824    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75    t    t    5   t   g  100.0    3    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71    t    f    0   f   s  120.0    0    1"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8a7f3a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((483, 15), (207, 15))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "83a579f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0.008282\n",
       "A2     0.022774\n",
       "A3     0.140787\n",
       "A4     0.008282\n",
       "A5     0.008282\n",
       "A6     0.008282\n",
       "A7     0.008282\n",
       "A8     0.140787\n",
       "A9     0.140787\n",
       "A10    0.140787\n",
       "A11    0.000000\n",
       "A12    0.000000\n",
       "A13    0.000000\n",
       "A14    0.014493\n",
       "A15    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the percentage of missing data within those variables\n",
    "\n",
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb8d77",
   "metadata": {},
   "source": [
    "## Add missing indicator with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "267729f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A1_NA</th>\n",
       "      <th>A3_NA</th>\n",
       "      <th>A4_NA</th>\n",
       "      <th>A5_NA</th>\n",
       "      <th>A6_NA</th>\n",
       "      <th>A7_NA</th>\n",
       "      <th>A8_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>a</td>\n",
       "      <td>46.08</td>\n",
       "      <td>3.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.375</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>8</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>396.0</td>\n",
       "      <td>4159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>a</td>\n",
       "      <td>15.92</td>\n",
       "      <td>2.875</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>0.085</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>b</td>\n",
       "      <td>36.33</td>\n",
       "      <td>2.125</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>0.085</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>b</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0.585</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>b</td>\n",
       "      <td>57.83</td>\n",
       "      <td>7.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>14.000</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2     A3 A4 A5  A6  A7      A8 A9 A10  A11 A12 A13    A14   A15  \\\n",
       "596  a  46.08  3.000  u  g   c   v   2.375  t   t    8   t   g  396.0  4159   \n",
       "303  a  15.92  2.875  u  g   q   v   0.085  f   f    0   f   g  120.0     0   \n",
       "204  b  36.33  2.125  y  p   w   v   0.085  t   t    1   f   g   50.0  1187   \n",
       "351  b  22.17  0.585  y  p  ff  ff   0.000  f   f    0   f   g  100.0     0   \n",
       "118  b  57.83  7.040  u  g   m   v  14.000  t   t    6   t   g  360.0  1332   \n",
       "\n",
       "     A1_NA  A3_NA  A4_NA  A5_NA  A6_NA  A7_NA  A8_NA  \n",
       "596      0      0      0      0      0      0      0  \n",
       "303      0      0      0      0      0      0      0  \n",
       "204      0      0      0      0      0      0      0  \n",
       "351      0      0      0      0      0      0      0  \n",
       "118      0      0      0      0      0      0      0  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add missing indicator\n",
    "\n",
    "for var in ['A1', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8']:\n",
    "\n",
    "    X_train[var+'_NA'] = np.where(X_train[var].isnull(), 1, 0)\n",
    "    X_test[var+'_NA'] = np.where(X_test[var].isnull(), 1, 0)\n",
    "\n",
    "    \n",
    "# check the new missing indicator variables\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5f89e2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14078674948240166, 0.14078674948240166)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the mean of the missing indicator should be the same as the \n",
    "# percentage of missing values in the original variable\n",
    "\n",
    "X_train['A3'].isnull().mean(), X_train['A3_NA'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af69844",
   "metadata": {},
   "source": [
    "## Adding missing indicator with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "39cf5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/univai-ghf/FeatureProcessingAndSelectionWorkshop/main/Data/creditApprovalUCI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "56c71936",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "33fdf39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MissingIndicator()"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator = MissingIndicator(error_on_new=True, features='missing-only')\n",
    "indicator.fit(X_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bf0867ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 13], dtype=int64)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the features with na:\n",
    "# the result shows the column index in the NumPy array\n",
    "\n",
    "indicator.features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9c622765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A1_NA</th>\n",
       "      <th>A2_NA</th>\n",
       "      <th>A3_NA</th>\n",
       "      <th>A4_NA</th>\n",
       "      <th>A5_NA</th>\n",
       "      <th>A6_NA</th>\n",
       "      <th>A7_NA</th>\n",
       "      <th>A8_NA</th>\n",
       "      <th>A9_NA</th>\n",
       "      <th>A10_NA</th>\n",
       "      <th>A14_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596</td>\n",
       "      <td>a</td>\n",
       "      <td>46.08</td>\n",
       "      <td>3.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.375</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>8</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>396.0</td>\n",
       "      <td>4159</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303</td>\n",
       "      <td>a</td>\n",
       "      <td>15.92</td>\n",
       "      <td>2.875</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>0.085</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204</td>\n",
       "      <td>b</td>\n",
       "      <td>36.33</td>\n",
       "      <td>2.125</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>0.085</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1187</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>351</td>\n",
       "      <td>b</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0.585</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>b</td>\n",
       "      <td>57.83</td>\n",
       "      <td>7.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>14.000</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1332</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index A1     A2     A3 A4 A5  A6  A7      A8 A9 A10  A11 A12 A13    A14  \\\n",
       "0    596  a  46.08  3.000  u  g   c   v   2.375  t   t    8   t   g  396.0   \n",
       "1    303  a  15.92  2.875  u  g   q   v   0.085  f   f    0   f   g  120.0   \n",
       "2    204  b  36.33  2.125  y  p   w   v   0.085  t   t    1   f   g   50.0   \n",
       "3    351  b  22.17  0.585  y  p  ff  ff   0.000  f   f    0   f   g  100.0   \n",
       "4    118  b  57.83  7.040  u  g   m   v  14.000  t   t    6   t   g  360.0   \n",
       "\n",
       "    A15  A1_NA  A2_NA  A3_NA  A4_NA  A5_NA  A6_NA  A7_NA  A8_NA  A9_NA  \\\n",
       "0  4159  False  False  False  False  False  False  False  False  False   \n",
       "1     0  False  False  False  False  False  False  False  False  False   \n",
       "2  1187  False  False  False  False  False  False  False  False  False   \n",
       "3     0  False  False  False  False  False  False  False  False  False   \n",
       "4  1332  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "   A10_NA  A14_NA  \n",
       "0   False   False  \n",
       "1   False   False  \n",
       "2   False   False  \n",
       "3   False   False  \n",
       "4   False   False  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with Sklearn we need to join the missing indicators dataframe\n",
    "# to the original X_train\n",
    "\n",
    "# let's create a column name for each of the new MissingIndicators\n",
    "indicator_cols = [c+'_NA' for c in X_train.columns[indicator.features_]]\n",
    "\n",
    "# and now let's concatenate the original dataset with the missing indicators\n",
    "X_train = pd.concat([\n",
    "    X_train.reset_index(),\n",
    "    pd.DataFrame(indicator.transform(X_train), columns = indicator_cols)],\n",
    "    axis=1)\n",
    "\n",
    "X_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
