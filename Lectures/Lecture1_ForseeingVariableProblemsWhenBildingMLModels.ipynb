{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24735c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# the dataset for the demo\n",
    "from sklearn.datasets import load_boston\n",
    "# for linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# for the Q-Q plots\n",
    "import scipy.stats as stats\n",
    "# the dataset for the demo\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the titanic dataset as example\n",
    "\n",
    "data = pd.read_csv('titanic.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c4857",
   "metadata": {},
   "source": [
    "## Checking the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a80973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print variable types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af97c32",
   "metadata": {},
   "source": [
    "## Inspecting unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect unique values - discrete variable\n",
    "data['sibsp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e410f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect unique values - continuous variable\n",
    "data['fare'].unique()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect unique values - categorical variable\n",
    "data['embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f37c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect unique values - mixed variable\n",
    "data['cabin'].unique()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf493caa",
   "metadata": {},
   "source": [
    "## Plots - Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of discrete variables often show\n",
    "# a bar plot shape, instead of continuous intervals\n",
    "\n",
    "data['sibsp'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd26b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of continuous variable\n",
    "\n",
    "data['fare'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plots for categorical variables\n",
    "\n",
    "data['embarked'].value_counts().plot.bar()\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.title('embakred - port')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e8e63",
   "metadata": {},
   "source": [
    "# Determining Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the selected variables for the recipe\n",
    "cols = ['GENDER', 'RFA_2', 'MDMAUD_A', 'RFA_2', 'DOMAIN', 'RFA_15']\n",
    "\n",
    "# load the dataset\n",
    "data = pd.read_csv('cup98LRN.txt', usecols=cols)\n",
    "\n",
    "# the dataset contains empty strings\n",
    "# which are in essence missing values\n",
    "# I replace those here\n",
    "data = data.replace(' ', np.nan)\n",
    "\n",
    "# let's inspect the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd99824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the following command we can learn the cardinality\n",
    "# of each of the loaded variables\n",
    "\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique() ignores missing data by default. If we want\n",
    "# to consider missing values as an additional category\n",
    "# we need to explicitly mention so, passing the argument\n",
    "# dropna=False\n",
    "\n",
    "data.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print the different unique labels\n",
    "data['GENDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the cardinality of the variables \n",
    "\n",
    "data.nunique().plot.bar(figsize=(12,6))\n",
    "\n",
    "# add labels and title\n",
    "plt.ylabel('Number of unique categories')\n",
    "plt.xlabel('Variables')\n",
    "plt.title('Cardinality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to evaluate the cardinality of only a subset \n",
    "# of columns from a data set, we can do so by passing the\n",
    "# columns of interest as follows:\n",
    "\n",
    "# evaluate cardinality of variables of choice\n",
    "data[['RFA_2', 'MDMAUD_A', 'RFA_2']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e204b0",
   "metadata": {},
   "source": [
    "# Pinpointing Rare Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Car Evaluation Dataset\n",
    "\n",
    "# this data does not include the columns, so we need\n",
    "# to indicate so while loading by passing header=None\n",
    "\n",
    "data = pd.read_csv('car.data', header=None)\n",
    "\n",
    "# add the column names manually\n",
    "# column descriptions are indicated in the UCI website\n",
    "data.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the cardinality of the variable\n",
    "# the number of unique categories\n",
    "\n",
    "data['class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect the name of the categories\n",
    "\n",
    "data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b94818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's calculate the frequency for each category\n",
    "\n",
    "# code as in book:\n",
    "\n",
    "label_freq = data['class'].value_counts() / len(data)\n",
    "\n",
    "# let's inspect the frequency of the labels\n",
    "label_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2815a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same code a bit nicer\n",
    "\n",
    "# now let's calculate the frequency for each category\n",
    "\n",
    "# first we calculate the total number of cars in the dataset\n",
    "total_cars = len(data)\n",
    "print('Total number of cars {}'.format(total_cars))\n",
    "\n",
    "# then we calculate label frequency\n",
    "# value_counts() counts the number of cars per label\n",
    "# by dividing by total cars we obtain the frequency\n",
    "\n",
    "label_freq = data['class'].value_counts() / total_cars\n",
    "\n",
    "# let's inspect the frequency of the labels\n",
    "label_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make plot with the category frequencies\n",
    "fig = label_freq.sort_values(ascending=False).plot.bar()\n",
    "\n",
    "# add a line to signal 5 % frequency limit\n",
    "# under which we will consider a category as rare\n",
    "fig.axhline(y=0.05, color='red')\n",
    "\n",
    "# add axis labels and title\n",
    "fig.set_ylabel('percentage of cars within each category')\n",
    "fig.set_xlabel('Variable: class')\n",
    "fig.set_title('Identifying Rare Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a016eb",
   "metadata": {},
   "source": [
    "# Identifying a Linear Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad435a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the the Boston House price data from scikit-learn\n",
    "\n",
    "# this is how we load the boston dataset from sklearn\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "# create a dataframe with the independent variables\n",
    "boston = pd.DataFrame(boston_dataset.data,\n",
    "                      columns=boston_dataset.feature_names)\n",
    "\n",
    "# add the target\n",
    "boston['MEDV'] = boston_dataset.target\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the information about the boston house prince dataset\n",
    "# get familiar with the variables before continuing with \n",
    "# the notebook\n",
    "\n",
    "# the aim is to predict the \"Median value of the houses\"\n",
    "# MEDV column of this dataset\n",
    "\n",
    "# and we have variables with characteristics about\n",
    "# the homes and the neighborhoods\n",
    "\n",
    "print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aead96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a dataframe with the variable x that\n",
    "# follows a normal distribution and shows a\n",
    "# linear relationship with y\n",
    "\n",
    "# this will provide the expected plots\n",
    "# i.e., how the plots should look like if the\n",
    "# linear assumption is met\n",
    "\n",
    "np.random.seed(29) # for reproducibility\n",
    "\n",
    "n = 200 # in the book we pass directly 200 within brackets, without defining n\n",
    "x = np.random.randn(n)\n",
    "y = x * 10 + np.random.randn(n) * 2\n",
    "\n",
    "data = pd.DataFrame([x, y]).T\n",
    "data.columns = ['x', 'y']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acedd1c5",
   "metadata": {},
   "source": [
    "Linear relationships can be assessed by scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the simulated data\n",
    "\n",
    "# this is how the scatter-plot looks like when\n",
    "# there is a linear relationship between X and Y\n",
    "\n",
    "sns.lmplot(x=\"x\", y=\"y\", data=data, order=1)\n",
    "# order 1 indicates that we want seaborn to\n",
    "# estimate a linear model (the line in the plot below)\n",
    "# between x and y\n",
    "\n",
    "plt.ylabel('Target')\n",
    "plt.xlabel('Independent variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we make a scatter plot for the boston\n",
    "# house price dataset\n",
    "\n",
    "# we plot the variable LAST (% lower status of the population)\n",
    "# vs the target MEDV (median value of the house)\n",
    "\n",
    "sns.lmplot(x=\"LSTAT\", y=\"MEDV\", data=boston, order=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d1fc5",
   "metadata": {},
   "source": [
    "Although not perfect, the relationship is fairly linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fbddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we plot CRIM (per capita crime rate by town)\n",
    "# vs the target MEDV (median value of the house)\n",
    "\n",
    "sns.lmplot(x=\"CRIM\", y=\"MEDV\", data=boston, order=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e786835a",
   "metadata": {},
   "source": [
    "Linear relationships can also be assessed by evaluating the residuals. Residuals are the difference between the value estimated by the linear relationship and the real output. If the relationship is linear, the residuals should be normally distributed and centered around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29003843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED DATA\n",
    "\n",
    "# step 1: build a linear model\n",
    "# call the linear model from sklearn\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "linreg.fit(data['x'].to_frame(), data['y'])\n",
    "\n",
    "# step 2: obtain the predictions\n",
    "# make the predictions\n",
    "pred = linreg.predict(data['x'].to_frame())\n",
    "\n",
    "# step 3: calculate the residuals\n",
    "error = data['y'] - pred\n",
    "\n",
    "# plot predicted vs real\n",
    "plt.scatter(x=pred, y=data['y'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Real value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: observe the distribution of the residuals\n",
    "\n",
    "# Residuals plot\n",
    "# if the relationship is linear, the noise should be\n",
    "# random, centered around zero, and follow a normal distribution\n",
    "\n",
    "# we plot the error terms vs the independent variable x\n",
    "# error values should be around 0 and homogeneously distributed\n",
    "\n",
    "plt.scatter(y=error, x=data['x'])\n",
    "plt.ylabel('Residuals')\n",
    "plt.xlabel('Independent variable x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: observe the distribution of the errors\n",
    "\n",
    "# plot a histogram of the residuals\n",
    "# they should follow a gaussian distribution\n",
    "# centered around 0\n",
    "\n",
    "sns.distplot(error, bins=30)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57abfccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do the same for the variable LSTAT of the boston\n",
    "# house price dataset from sklearn\n",
    "\n",
    "# call the linear model from sklearn\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "linreg.fit(boston['LSTAT'].to_frame(), boston['MEDV'])\n",
    "\n",
    "# make the predictions\n",
    "pred = linreg.predict(boston['LSTAT'].to_frame())\n",
    "\n",
    "# calculate the residuals\n",
    "error = boston['MEDV'] - pred\n",
    "\n",
    "# plot predicted vs real\n",
    "plt.scatter(x=pred, y=boston['MEDV'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals plot\n",
    "\n",
    "# if the relationship is linear, the noise should be\n",
    "# random, centered around zero, and follow a normal distribution\n",
    "\n",
    "plt.scatter(y=error, x=boston['LSTAT'])\n",
    "plt.ylabel('Residuals')\n",
    "plt.xlabel('LSTAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the residuals\n",
    "# they should follow a gaussian distribution\n",
    "sns.distplot(error, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38f5a8",
   "metadata": {},
   "source": [
    "For this particular case, the residuals are centered around zero, but they are not homogeneously distributed across the values of LSTAT. Bigger and smaller values of LSTAT show higher residual values. In addition, we see in the histogram that the residuals do not adopt a strictly Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240875d2",
   "metadata": {},
   "source": [
    "# Identifying a Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb627af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the the Boston House price data\n",
    "\n",
    "# this is how we load the boston dataset from sklearn\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "# create a dataframe with the independent variables\n",
    "boston = pd.DataFrame(boston_dataset.data,\n",
    "                      columns=boston_dataset.feature_names)\n",
    "\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc97905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the information about the boston house prince dataset\n",
    "# get familiar with the variables before continuing with \n",
    "# the notebook\n",
    "\n",
    "# the aim is to predict the \"Median value of the houses\"\n",
    "# MEDV column of this dataset\n",
    "\n",
    "# and we have variables with characteristics about\n",
    "# the homes and the neighborhoods\n",
    "\n",
    "print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a dataframe with the variable x that\n",
    "# follows a normal distribution \n",
    "\n",
    "# this will provide the expected plots\n",
    "# i.e., how the plots should look like if the\n",
    "# assumption is met\n",
    "\n",
    "np.random.seed(29) # for reproducibility\n",
    "\n",
    "n = 200 # in the book, we pass 200 within brackets directly, without defining n\n",
    "x = np.random.randn(n)\n",
    "\n",
    "data = pd.DataFrame([x]).T\n",
    "data.columns = ['x']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924b4d5",
   "metadata": {},
   "source": [
    "Normality can be assessed by histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the simulated independent variable x\n",
    "# which we know follows a Gaussian distribution\n",
    "\n",
    "sns.distplot(data['x'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63eafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the variable RM from the boston\n",
    "# house price dataset from sklearn\n",
    "# RM is the average number of rooms per dwelling\n",
    "\n",
    "sns.distplot(boston['RM'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the variable LSTAT\n",
    "# (% lower status of the population)\n",
    "\n",
    "sns.distplot(boston['LSTAT'], bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80314d33",
   "metadata": {},
   "source": [
    "Normality can be also assessed by Q-Q plots. In a Q-Q plot we plot the quantiles of the variable in the y-axis and the expected quantiles of the normal distribution in the x-axis. If the variable follows a normal distribution, the dots in the Q-Q plot should fall in a 45 degree diagonal line as indicated below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the Q-Q plot for the simualted data.\n",
    "# the dots should adjust to the 45 degree line\n",
    "\n",
    "stats.probplot(data['x'], dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0084e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same for RM\n",
    "stats.probplot(boston['RM'], dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24944ec",
   "metadata": {},
   "source": [
    "Most of the observations of RM fall on the 45 degree line, which suggests that the distribution is approximately Gaussian, with some deviation towards the larger and smaller values of the variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19464003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for comparison, let's go ahead and plot CRIM\n",
    "stats.probplot(boston['CRIM'], dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44db58",
   "metadata": {},
   "source": [
    "CRIM does not follow a Gaussian distribution as most of its observations deviate from the 45 degree line in the Q-Q plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a85031",
   "metadata": {},
   "source": [
    "# Distribution Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb02e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the the Boston House price data\n",
    "\n",
    "# this is how we load the boston dataset from sklearn\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "# create a dataframe with the independent variables\n",
    "boston = pd.DataFrame(boston_dataset.data,\n",
    "                      columns=boston_dataset.feature_names)\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0761267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the information about the boston house prince dataset\n",
    "# get familiar with the variables before continuing with \n",
    "# the notebook\n",
    "\n",
    "# the aim is to predict the \"Median value of the houses\"\n",
    "# MEDV column of this dataset\n",
    "\n",
    "# and we have variables with characteristics about\n",
    "# the homes and the neighborhoods\n",
    "\n",
    "print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78667b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.hist(bins=30, figsize=(12,12), density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95448f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4f197a",
   "metadata": {},
   "source": [
    "# Highlighting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the the Boston House price data\n",
    "\n",
    "# load the boston dataset from sklearn\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "# create a dataframe with the independent variables\n",
    "# indicated below: \n",
    "# I will use only 3 of the total variables for this demo\n",
    "\n",
    "boston = pd.DataFrame(boston_dataset.data,\n",
    "                      columns=boston_dataset.feature_names)[[\n",
    "                          'RM', 'LSTAT', 'CRIM'\n",
    "                      ]]\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad07aae",
   "metadata": {},
   "source": [
    "In the boxplot displayed below, the IQR is indicated by the box, the median is indicated by the line within the box, the top and bottom edges of the box correspond to the 75th and 25th quantile, and the whiskers  mark the proximity rule boundaries as described above. Values that fall outside the whiskers are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot\n",
    "plt.figure(figsize=(3,6))\n",
    "sns.boxplot(y=boston['RM'])\n",
    "plt.title('Boxplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot\n",
    "plt.figure(figsize=(3,6))\n",
    "sns.boxplot(y=boston['LSTAT'])\n",
    "plt.title('Boxplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not let's find in a dataframe those outliers:\n",
    "\n",
    "# the function finds the upper and lower boundaries\n",
    "# using the IQR proximity rule\n",
    "\n",
    "# function as presented in the book\n",
    "\n",
    "def find_boundaries(df, variable):\n",
    "\n",
    "    # distance passed as an argument, gives us the option to\n",
    "    # estimate 1.5 times or 3 times the IQR to calculate\n",
    "    # the boundaries.\n",
    "\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR * 1.5)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR * 1.5)\n",
    "\n",
    "    return upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ff657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find the boudaries for the variable RM\n",
    "\n",
    "upper_boundary, lower_boundary = find_boundaries(boston, 'RM')\n",
    "upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96474181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not let's find in a dataframe those outliers:\n",
    "\n",
    "# the function finds the upper and lower boundaries\n",
    "# using the IQR proximity rule\n",
    "\n",
    "# alternative, also presented in the book\n",
    "# passing the distance as a function argument\n",
    "# to allow for versatility\n",
    "\n",
    "def find_boundaries(df, variable, distance):\n",
    "\n",
    "    # distance passed as an argument, gives us the option to\n",
    "    # estimate 1.5 times or 3 times the IQR to calculate\n",
    "    # the boundaries.\n",
    "\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n",
    "\n",
    "    return upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find the boudaries for the variable RM\n",
    "\n",
    "upper_boundary, lower_boundary = find_boundaries(boston, 'RM', 1.5)\n",
    "upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9f2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's flag the outliers in the data set\n",
    "\n",
    "outliers = np.where(boston['RM'] > upper_boundary, True,\n",
    "                    np.where(boston['RM'] < lower_boundary, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many outliers did we find?\n",
    "outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print a few of them\n",
    "\n",
    "outliers_df = boston.loc[outliers, 'RM']\n",
    "outliers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = boston.loc[~outliers, 'RM']\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1d7c1",
   "metadata": {},
   "source": [
    "# Comparing Feature Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12edf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the the Boston House price data\n",
    "\n",
    "# this is how we load the boston dataset from sklearn\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "# create a dataframe with the independent variables\n",
    "data = pd.DataFrame(boston_dataset.data,\n",
    "                      columns=boston_dataset.feature_names)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the values of those variables\n",
    "# to get an idea of the feature magnitudes\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac9fa1",
   "metadata": {},
   "source": [
    "In the table we observe the main statistics of the variables, e.g., the 25th, 50th and 75th quantiles, the mean, standard deviation and minimum and maximum value. Comparing these parameters we can quickly understand whether our features are in a similar scale. In this case, they are clearly not.\n",
    "\n",
    "CRIM takes values 0-89 whereas CHAS takes values 0 to 1, and RM takes values 3.5 to 8.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now calculate the range of the variables\n",
    "\n",
    "data.max() - data.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2832f9",
   "metadata": {},
   "source": [
    "The ranges of the variables, as expected are quite different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
